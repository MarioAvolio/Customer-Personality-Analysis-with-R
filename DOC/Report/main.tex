%++++++++++++++++++++++++++++++++++++++++
% Don't modify this section unless you know what you're doing!
\documentclass[letterpaper,11pt]{article}
\usepackage{natbib}
\usepackage[italian]{babel}
\usepackage{float}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{listings}
\usepackage[svgnames]{xcolor}
\usepackage{babel,blindtext}
\usepackage{titlesec}

% tree structure
\usepackage{forest}
%%%%%%%%%


\usepackage[font=small,labelfont=bf]{caption}

\usepackage{afterpage}

\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}


\setcounter{secnumdepth}{4}

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}


\lstset{frame=none,
  language=R,
  showstringspaces=false,
  columns=flexible,
  numbers=none,
  basicstyle={\small\ttfamily},
  keywordstyle=\color{Blue},
  stringstyle=\color{Red},
  commentstyle=\color{DarkGreen},
  breaklines=true,
  breakatwhitespace=true,
  moredelim=**[is][\color{blue}]{@}{@},
  tabsize=3}
  
\bibliographystyle{unsrtnat}
\usepackage{tabularx} % extra features for tabular environment
\usepackage{amsmath}  % improve math presentation
\usepackage{graphicx} % takes care of graphic including machinery
\usepackage[margin=1in,letterpaper]{geometry} % decreases margins
%\usepackage{cite} % takes care of citations
\usepackage[final]{hyperref} % adds hyper links inside the generated pdf file
\hypersetup{
	colorlinks=true,       % false: boxed links; true: colored links
	linkcolor=blue,        % color of internal links
	citecolor=blue,        % color of links to bibliography
	filecolor=magenta,     % color of file links
	urlcolor=blue         
}
%+++++++++++++++++++++++++++++++++++++++
\begin{document}
\title{Machine Learning Project \\\textbf{Customer Personality Analysis}}
%\author{Mario Avolio}

\author{
  Mario Avolio\\
  \texttt{880995}
  \and
  Rocco Gianni Rapisarda\\
  \texttt{845197}
}
\date{\today}
\maketitle

\begin{abstract}
L'apprendimento automatico e la statistica sono discipline strettamente collegate. Secondo \href{https://en.wikipedia.org/wiki/Michael\_I.\_Jordan}{Michael I. Jordan}, le idee dell'apprendimento automatico, dai principi metodologici agli strumenti teorici, sono stati sviluppati prima in statistica. In questo elaborato si riporta l'attività di sviluppo e sperimentazione di diversi modelli di \textbf{Machine Learning} per l'analisi approfondita dei clienti ideali per una generica azienda. La concentrazione è stata focalizzata soprattutto sul \textbf{Clustering} mediante l'algoritmo \textbf{K-Means}, sebbene nel corso della trattazione si esporranno anche altre metodologie utilizzate per l'analisi dei dati.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                              %
%                                                              %
%                                                              %
%                         NEW SECTION                          %
%                                                              %
%                                                              %
%                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Descrizione del dominio di riferimento e obiettivi dell’elaborato}
Molto spesso lo sviluppo di nuovi prodotti o servizi è attivato dall’imitazione dei concorrenti e da analisi di mercato generiche, mentre al cliente si dedica poca attenzione. L’acquisto è prima di tutto un’esperienza ed è necessario comprendere quali bisogni la guidano: solo così ogni segmento di mercato individuato sarà connesso con la capacità dell’azienda di soddisfare le aspettative dei clienti, comprese quelle inespresse. Progettare, sviluppare e vendere prodotti non connessi con il proprio target rappresenta un costo insostenibile, mentre è necessario progettare uno sviluppo in linea con la \textit{customer satisfaction}. Per questo motivo \href{https://github.com/MarioAvolio/Customer-Personality-Analysis-with-R}{Customer Personality Analysis} riguarda un'analisi dettagliata dei clienti ideali per una generica azienda. Il compito fondamentale è quello di aiutare un'attività commerciale a comprendere meglio i propri compratori al fine di rendere più semplice la modifica e la scelta dei propri prodotti, in relazione alle esigenze richieste dagli acquirenti. L'obiettivo che ha spinto ad analizzare questo insieme di dati è inerente alle \textbf{diverse} personalità e comportamenti che gli acquirenti assumono durante il ruolo di potenziali clienti aziendali. Per questo motivo le aziende non possono adottare lo stesso approccio per ogni tipologia di plausibile compratore. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                              %
%                                                              %
%                                                              %
%                         NEW SECTION                          %
%                                                              %
%                                                              %
%                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%% 

%%%%%%% 
\section{Scelte di design}
Per gestire al meglio la giusta separazione tra gli elementi del progetto si è deciso di sfruttare un particolare pattern strutturale definito dallo schema sottostante. Il modello, cattura il comportamento dell'applicazione in termini di dominio del problema e gestisce direttamente i dati, la logica e le regole del progetto. 


\begin{forest}
  for tree={
    font=\ttfamily,
    grow'=0,
    child anchor=west,
    parent anchor=south,
    anchor=west,
    calign=first,
    edge path={
      \noexpand\path [draw, \forestoption{edge}]
      (!u.south west) +(7.5pt,0) |- node[fill,inner sep=1.25pt] {} (.child anchor)\forestoption{edge label};
    },
    before typesetting nodes={
      if n=1
        {insert before={[,phantom]}}
        {}
    },
    fit=band,
    before computing xy={l=15pt},
  }
[Customer Personality Analysis Project
  [ML-Porject.Rproj]
  [Data
    [marketing\_campaign.csv]
  ]
  [DOC
    [Presentation
    [...]]
    [Report
    [...]]
  ]
  [Script
  [D-TREE.R]
  [DescriptionOfData.R]
  [EDA.R]
  [K-MEANS.R]
  [PCA.R]
  [D-TREE-Model Evaluation.R]
  [Functions
  [Functions.R]]
  ]
  [Output
  [Plots
  [...]]
  [Data
  [...]]]
  [Other
  [...]]
  [README.MD]
]
\end{forest}\\
E' bene precisare che all'interno del file \textbf{README.MD} sono precisate tutte le librerie utilizzate.
\paragraph*{Data} 
Questa è la sottocartella in cui vengono salvati tutti i file che devono essere letti in R per eseguire l' analisi. Essi potrebbero essere file SPSS (*.sav), file Excel/CSV, file .FST o .RDS. L'idea chiave è quella di trattare, all'interno di questa cartella, file di dati di origine che in nessun momento R dovrebbe salvare o modificare al fine di garantirne la riproducibilità.  In particolare si può notare l'esistenza del dataset analizzato all'interno di questa cartella. 
\paragraph*{Script} 
All'interno di questa sottocartella è possibile notare tutti gli script per l'analisi dei dati. Ogni script è opportunamente collegato ai precedenti per favoreggiarne l'esecuzione immediata. Si può anche notare la cartella \textit{Functions} dove è possibile trovare una serie di funzioni di utilità per la chiarezza e la compattezza del codice.
\paragraph*{Output} 
All'interno di questa sottocartella è doveroso notare l'insieme dei dati in output dall'esecuzione del codice. In particolare sono stati inseriti numerosi grafici nati dall'analisi del dataset.

%%%%%%% 

%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                              %
%                                                              %
%                                                              %
%                         NEW SECTION                          %
%                                                              %
%                                                              %
%                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Descrizione dei Dati}


\subsection{Attributi}
Si fornisce la descrizione originale degli attributi analizzati.
\subsubsection*{People}
\begin{itemize}
    \item ID: Customer's unique identifier
    \item Year\_Birth: Customer's birth year
    \item Education: Customer's education level
    \item Marital\_Status: Customer's marital status
    \item Income: Customer's yearly household income
    \item Kidhome: Number of children in customer's household
    \item Teenhome: Number of teenagers in customer's household
    \item Dt\_Customer: Date of customer's enrollment with the company
    \item Recency: Number of days since customer's last purchase
    \item Complain: 1 if the customer complained in the last 2 years, 0 otherwise
\end{itemize}


\subsubsection*{Products}
\begin{itemize}
\item MntWines: Amount spent on wine in last 2 years
\item MntFruits: Amount spent on fruits in last 2 years
\item MntMeatProducts: Amount spent on meat in last 2 years
\item MntFishProducts: Amount spent on fish in last 2 years
\item MntSweetProducts: Amount spent on sweets in last 2 years
\item MntGoldProds: Amount spent on gold in last 2 years
\end{itemize}

\subsubsection*{Promotion}
\begin{itemize}
\item NumDealsPurchases: Number of purchases made with a discount
\item AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise
\item AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise
\item AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise
\item AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise
\item AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise
 \item Response: 1 if customer accepted the offer in the last campaign, 0 otherwise
\end{itemize}

\subsubsection*{Place}
\begin{itemize}
\item NumWebPurchases: Number of purchases made through the company’s website
\item NumCatalogPurchases: Number of purchases made using a catalogue
\item NumStorePurchases: Number of purchases made directly in stores
\item NumWebVisitsMonth: Number of visits to company’s website in the last month
\end{itemize}
La tabella \ref{fig:sapply(dataSet, class)} fornisce un'iniziale descrizione della tipologia di variabili presenti nel dataset. \\
\begin{table}[H]
\centering
\begin{tabular}{rl}
  \hline
 & sapply(dataSet, class) \\ 
  \hline
ID & integer \\ 
  Year\_Birth & integer \\ 
  Education & character \\ 
  Marital\_Status & character \\ 
  Income & integer \\ 
  Kidhome & integer \\ 
  Teenhome & integer \\ 
  Dt\_Customer & character \\ 
  Recency & integer \\ 
  MntWines & integer \\ 
  MntFruits & integer \\ 
  MntMeatProducts & integer \\ 
  MntFishProducts & integer \\ 
  MntSweetProducts & integer \\ 
  MntGoldProds & integer \\ 
  NumDealsPurchases & integer \\ 
  NumWebPurchases & integer \\ 
  NumCatalogPurchases & integer \\ 
  NumStorePurchases & integer \\ 
  NumWebVisitsMonth & integer \\ 
  AcceptedCmp3 & integer \\ 
  AcceptedCmp4 & integer \\ 
  AcceptedCmp5 & integer \\ 
  AcceptedCmp1 & integer \\ 
  AcceptedCmp2 & integer \\ 
  Complain & integer \\ 
  Z\_CostContact & integer \\ 
  Z\_Revenue & integer \\ 
  Response & integer \\ 
   \hline
\end{tabular}
\caption{Output funzione \textit{sapply(dataSet, class)}}
\label{fig:sapply(dataSet, class)}
\end{table}

\subsection{Prime analisi}
Prima di fornire un'analisi dettagliata degli elementi del dataset si è ritenuto necessario effettuare una prima ispezione di alto livello, senza entrare nel dettaglio di ciascun attributo. Il dataset viene importato mediante la funzione:
\begin{lstlisting}[language=R]
dataSet <- read.csv(paste(getwd(),"/Data/marketing_campaign.csv",sep = ""), header=TRUE, sep="\t",  stringsAsFactors=F) # use TAB as separator!
\end{lstlisting}

\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/DESCRIPTION/DESCRIPTION003.png}
    \caption{BoxPlot Income}
    \label{fig:BoxPlotIncome}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/DESCRIPTION/DESCRIPTION020.png}
    \caption{Istogramma di Income}
    \label{fig:Histogram_Income}
  \end{minipage}
\end{figure}


\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/DESCRIPTION/DESCRIPTION018.png}
    \caption{BoxPlot Z\_CostContact}
    \label{fig:ZRevenue}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/DESCRIPTION/DESCRIPTION019.png}
    \caption{BoxPlot Z\_Revenue}
      \label{fig:ZCostContact}
  \end{minipage}
\end{figure}





Durante questa prima indagine sono stati effettuati controlli di base sulle variabili. In particolare, dalle analisi dei boxplot riportati rispettivamente nelle figure \ref{fig:ZCostContact} e \ref{fig:ZRevenue} è doveroso notare la mancanza di \textbf{varianza} di tali variabili, questo aspetto sarà successivamente preso in considerazione durante la fase di preprocessing.\\ Inoltre durante l'analisi delle figure \ref{fig:BoxPlotIncome} e \ref{fig:Histogram_Income}, mediante un apposito \textit{warning} durante l'esecuzione del codice R, si è notata la presenza di alcuni valori mancanti.
\begin{lstlisting}[language=R]
hist(dataSet$Income,40,col="#adcae6")
ggplot(dataSet, aes(y = Income)) + geom_boxplot()
n_miss(dataSet) # counting the total number of missing values in the data
miss_var_summary(dataSet) # Summarizing missingness in each variable 
\end{lstlisting}
La tabella \ref{fig:miss_var_summary(dataSet)} mostra l'output del comando \textit{miss\_var\_summary(dataSet)}, dove si possono notare 24 valori mancanti nella variabile \textit{Income}.
\begin{table}[H]
\centering
\begin{tabular}{rlrr}
  \hline
 & variable & n\_miss & pct\_miss \\ 
  \hline
1 & Income &  24 & 1.07 \\ 
  2 & ID &   0 & 0.00 \\ 
  3 & Year\_Birth &   0 & 0.00 \\ 
  4 & Education &   0 & 0.00 \\ 
  5 & Marital\_Status &   0 & 0.00 \\ 
  6 & Kidhome &   0 & 0.00 \\ 
  7 & Teenhome &   0 & 0.00 \\ 
  8 & Dt\_Customer &   0 & 0.00 \\ 
  9 & Recency &   0 & 0.00 \\ 
  10 & MntWines &   0 & 0.00 \\ 
  11 & MntFruits &   0 & 0.00 \\ 
  12 & MntMeatProducts &   0 & 0.00 \\ 
  13 & MntFishProducts &   0 & 0.00 \\ 
  14 & MntSweetProducts &   0 & 0.00 \\ 
  15 & MntGoldProds &   0 & 0.00 \\ 
  16 & NumDealsPurchases &   0 & 0.00 \\ 
  17 & NumWebPurchases &   0 & 0.00 \\ 
  18 & NumCatalogPurchases &   0 & 0.00 \\ 
  19 & NumStorePurchases &   0 & 0.00 \\ 
  20 & NumWebVisitsMonth &   0 & 0.00 \\ 
  21 & AcceptedCmp3 &   0 & 0.00 \\ 
  22 & AcceptedCmp4 &   0 & 0.00 \\ 
  23 & AcceptedCmp5 &   0 & 0.00 \\ 
  24 & AcceptedCmp1 &   0 & 0.00 \\ 
  25 & AcceptedCmp2 &   0 & 0.00 \\ 
  26 & Complain &   0 & 0.00 \\ 
  27 & Z\_CostContact &   0 & 0.00 \\ 
  28 & Z\_Revenue &   0 & 0.00 \\ 
  29 & Response &   0 & 0.00 \\ 
   \hline
\end{tabular}

    \caption{Output funzione \textit{miss\_var\_summary(dataSet)}}
   
   \label{fig:miss_var_summary(dataSet)}
\end{table}

\newpage

\subsection{Data Preprocessing}
La fase di \textit{data preprocessing} è risultata fondamentale per la buona riuscita dell'analisi dei dati preposti. Essa si basa su quattro principali stadi:
\begin{itemize}
    \item Refactor del dataset
    \item Risoluzione dei valori mancanti nella variabile \textit{income}
    \item Splitting del dataset in \textit{trainingSet} e \textit{testSet}
    \item Feature Scaling
\end{itemize}
\subsubsection{Refactor del Dataset}
In questa fase ci si è concentrati su diversi aspetti migliorativi. In primo luogo si è voluto essettuare un'azione di incorporamento di dati. La motivazione è dovuta principalmente alla presenza di dati ridondati all'interno di molte variabili, in particolare si vuole porre l'attenzione su: \textit{Marital\_Status} e \textit{Education}. Difatti utilizzando la funzione \textit{unique}, come riportato nelle tabelle \ref{fig:unique(dataSetEducation)} e \ref{fig:unique(dataSetMaritalStatus)}, si è potuto rilevare la presenza di troppi elementi superflui.
\begin{table}[H]
\centering
\begin{tabular}{rl}
  \hline
 & unique(dataSet\$Marital\_Status) \\ 
  \hline
1 & Single \\ 
  2 & Together \\ 
  3 & Married \\ 
  4 & Divorced \\ 
  5 & Widow \\ 
  6 & Alone \\ 
  7 & Absurd \\ 
  8 & YOLO \\ 
  \hline
\end{tabular}
\caption{Output $unique(dataSet\$Marital\_Status)$}
\label{fig:unique(dataSetMaritalStatus)}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{rl}
  \hline
 & unique(dataSet\$Education) \\ 
  \hline
1 & Graduation \\ 
  2 & PhD \\ 
  3 & Master \\ 
  4 & Basic \\ 
  5 & 2n Cycle \\ 
  \hline
\end{tabular}
\caption{Output $unique(dataSet\$Education)$}
\label{fig:unique(dataSetEducation)}
\end{table}

Come mostrato dal codice sottostante, l'obiettivo è stato quello di diminuire, per favorire l'analisi mediante i diversi algoritmi utilizzati, in numero delle categorie di valori per le relative variabili. 
\begin{lstlisting}[language=R]
# ------------------------------------- COLLAPSING
#Collapsing marital Status into two categories: Single & Couple
unique(dataSet$Marital_Status)
dataSet <- mutate(dataSet, Marital_Status = replace(Marital_Status, Marital_Status == "Divorced" | Marital_Status == "Widow" | Marital_Status == "Alone" | Marital_Status == "Absurd" | Marital_Status == "YOLO", "Single"))
dataSet <- mutate(dataSet, Marital_Status = replace(Marital_Status, Marital_Status == "Together" | Marital_Status == "Married", "Couple"))

#Collapsing the Education into two Categories: graduate and non-graduate
unique(dataSet$Education)
dataSet <- mutate(dataSet, Education = replace(Education, Education == "Graduation"| Education == "PhD" | Education == "Master", "graduate"))
dataSet <- mutate(dataSet, Education = replace(Education, Education == "Basic"| Education == "2n Cycle", "non-graduate"))
# ------------------------------------- 
\end{lstlisting}
In particolar modo si è deciso di fornire due possibili valori riassuntivi per ciascuna variabile, come indicato nelle tabelle \ref{fig:unique(dataSetEducation)2} e \ref{fig:unique(dataSetMaritalStatus)2}.

\begin{table}[H]
\centering
\begin{tabular}{rl}
  \hline
 & unique(dataSet\$Education) \\ 
  \hline
1 & graduate \\ 
  2 & non-graduate \\ 
   \hline
\end{tabular}
\caption{Output $unique(dataSet\$Education)$ dopo la procedura di \textit{collapsing} dei dati}
\label{fig:unique(dataSetEducation)2}
\end{table}


\begin{table}[H]
\centering
\begin{tabular}{rl}
  \hline
 & unique(dataSet\$Marital\_Status) \\ 
  \hline
1 & Single \\ 
  2 & Couple \\ 
   \hline
\end{tabular}
\caption{Output $unique(dataSet\$Marital\_Status)$ dopo la procedura di \textit{collapsing} dei dati}
\label{fig:unique(dataSetMaritalStatus)2}
\end{table}

La fase di \textit{refactoring} si è anche occupata della convesione in \textit{factor} degli elementi \textit{character} all'interno dell'insieme di dati.
Il codice sottostante mostra la procedura seguita. Le tabelle \ref{fig:head(dataSetEducation)} e \ref{fig:head(dataSetMaritalStatus)} mostrano il risultato di tale procedura.
\begin{lstlisting}[language=R]
# ------------------------------------- CONVERSION
#Converting them to factors
dataSet <- mutate(dataSet, Marital_Status = as.factor(Marital_Status), Education = as.factor(Education))

# Encoding the categorical features to numeric
dataSet <- mutate(dataSet, Education = case_when(Education == "graduate" ~ 1,
                                                     Education == "non-graduate" ~ 0))
dataSet <- mutate(dataSet, Marital_Status = case_when(Marital_Status == "Couple" ~ 1,
                                                          Marital_Status == "Single" ~ 0))
\end{lstlisting}

\begin{table}[H]
\centering
\begin{tabular}{rr}
  \hline
 & head(dataSet\$Marital\_Status) \\ 
  \hline
1 & 0.00 \\ 
  2 & 0.00 \\ 
  3 & 1.00 \\ 
  4 & 1.00 \\ 
  5 & 1.00 \\ 
  6 & 1.00 \\ 
   \hline
\end{tabular}
\caption{Output $head(dataSet\$Marital\_Status)$}
\label{fig:head(dataSetMaritalStatus)}
\end{table}
\begin{table}[H]
\centering
\begin{tabular}{rr}
  \hline
 & head(dataSet\$Education) \\ 
  \hline
1 & 1.00 \\ 
  2 & 1.00 \\ 
  3 & 1.00 \\ 
  4 & 1.00 \\ 
  5 & 1.00 \\ 
  6 & 1.00 \\ 
   \hline
\end{tabular}
\caption{Output $head(dataSet\$Education)$}
\label{fig:head(dataSetEducation)}
\end{table}

Questa fase si è anche occupata della creazione di nuove variabili partendo da quelle già presenti all'interno da quelle già esistenti. Si ponga l'attenzione in particolar modo alle \textbf{categorie} di variabili \textit{Mnt}, \textit{Accepted}, \textit{KidHome}, \textit{TeenHome}. Tali categorie possono essere sommate per creare nuove variabili riassuntive. Il codice seguente e la tabella \ref{fig:Totalspent&TotalCampains&TotalChilds} ne riportano un esempio:
\begin{lstlisting}[language=R]
# ------------------------------------- TOTAL
#Creating a new variable:Total_spent
dataSet <- mutate(dataSet, Total_spent = MntWines + MntFruits + MntMeatProducts + MntFishProducts + MntSweetProducts + MntGoldProds)

# Details about previous campains also combined. Creating a new variable:Total_Campains
dataSet <- mutate(dataSet, Total_Campains = AcceptedCmp1 + AcceptedCmp2 + AcceptedCmp3 + AcceptedCmp4 + AcceptedCmp5)

# These variables can be combined and we can get the no of children for the dataSet. Creating a new variable:Total_Childs
dataSet <- mutate(dataSet, Total_Childs = Kidhome + Teenhome)
# ------------------------------------- 
\end{lstlisting}
\begin{table}[H]
\centering
\begin{tabular}{rrrr}
  \hline
 & Total\_spent & Total\_Campains & Total\_Childs \\ 
  \hline
1 & 1617 &   0 &   0 \\ 
  2 &  27 &   0 &   2 \\ 
  3 & 776 &   0 &   0 \\ 
  4 &  53 &   0 &   1 \\ 
  5 & 422 &   0 &   1 \\ 
  6 & 716 &   0 &   1 \\ 
   \hline
\end{tabular}
\caption{Primi valori delle variabili Total\_spent \& Total\_Campains \& Total\_Childs}
\label{fig:Totalspent&TotalCampains&TotalChilds}
\end{table}

Per finire è doveroso sottolineare che in questa sezioni ci si è anche occupati dell'eliminazione delle variabili superflue, come \textit{Z\_CostContact} e \textit{Z\_Revenue} che non hanno varianza, e della sostituzione della varibile \textit{Year\_Birth} con \textit{Age}.
\begin{lstlisting}[language=R]
# we can calculate customer age from the birth year. It will be more usefull to our analysis.
# creating a new variable Age from Year of Birth 
thisYear <- as.numeric(format(as.Date(Sys.Date(), format="%d-%m-%Y"),"%Y"))
thisYear
dataSet <- mutate(dataSet, Age = thisYear - Year_Birth)
#Dropping some redundant features
dataSet <- select(dataSet, - ID, - Year_Birth, - Z_CostContact, - Z_Revenue, -Dt_Customer)
\end{lstlisting}
\subsubsection{Risoluzione dei valori mancanti}
Come mostrato nel codice sottostante, non si è deciso di eliminare completamente i valori mancanti all'interno della variabile \textit{income}, bensì si è adottata un'altra strategia: la sostituzione con il valore medio della variabile stessa.
\begin{lstlisting}[language=R]
dataSet$Income <- ifelse(is.na(dataSet$Income), # is.na check is a value is not available
                          ave(dataSet$Income, FUN = function(x) mean(x, na.rm = TRUE)), # if is not available change with average
                          dataSet$Income # else ) 
\end{lstlisting}
\subsubsection{Splitting in TrainingSet e TestSet}
Al fine di una buona analisi dei dati, si è deciso di suddividere il dataset iniziale in due più ridotti: l'insieme di allenamento e quello di testing. Il codice sottostante mostra la procedura effettuata.
\begin{lstlisting}[language=R]
set.seed(17538)
split <- sample.split(dataSet$Response, SplitRatio = 0.8)
trainingSet <- subset(dataSet, split == TRUE)
testSet <- subset(dataSet, split == FALSE)
\end{lstlisting}
\subsubsection{Feature Scaling}
E' opportuno sottolineare che si è deciso di normalizzare i valori delle variabili al fine di poter utilizzare al meglio gli algoritmi di machine learning che verranno descritti nel corso di questa trattazione. Il codice seguente mostra un esempio:
\begin{lstlisting}[language=R]
trainingSet_scaled <- as.data.frame(scale(trainingSet[, getIndipendentNumbersOfCol()]))
testSet_scaled <- as.data.frame(scale(testSet[, getIndipendentNumbersOfCol()]))
dataSet_scaled <- as.data.frame(scale(dataSet[, getIndipendentNumbersOfCol()]))
\end{lstlisting}

\subsection{EDA}
Dopo aver eseguito il preprocessing dei dati si è passati ad un'analisi esplorativa dei dati.
Le prime variabili che sono state analizzate sono state \textit{Age, Income} e \textit{Total\_Spent} rappresentando i grafici a torta.

\begin{lstlisting}[language=R]
# Age Range
ageRange <- cut(dataSet$Age, breaks = c(24, 64, Inf), include.lowest = T,
                ordered_result = T, labels = c("Adult", "Senior"))
dataSet <- mutate(dataSet, Age_range = ageRange)
# Income Range
incomeRange <- cut(dataSet$Income, 
                   calculateBreaksFromSummary(dataSet$Income),
                   labels = c("low", "low medium", "medium high", "high"))
dataSet <- mutate(dataSet, Income_range = incomeRange)
# Spent Range
spentRange <- cut(dataSet$Total_spent, 
                  calculateBreaksFromSummary(dataSet$Total_spent),
                  labels = c("low", "low medium", "medium high", "high"))
dataSet <- mutate(dataSet, Spent_range = spentRange)
\end{lstlisting}

Il primo grafico a torta \ref{fig:PiePlotYearBirth} è relativo alla variabile Age, il colore viola rappresenta il valore \textit{Adult} mentre il colore giallo \textit{Senior}. Dal grafico si ricava che la maggior parte degli individui è \textit{Adult}.
Il secondo, il grafico \ref{fig:PiePlotIncome} rappresenta la variabile \textit{income}, il dataset è equi-distribuito in questo caso.
La distribuizione dei valori che assume la variabile \textit{Total spent} è raffigurata nella Figura \ref{fig:PiePlotIncome}. Da essa si ricava che low e high sono simili mentre il valore più frequente è \textit{low medium}.\\

\begin{figure}[H]
     \begin{center}
%
        \subfigure[PiePlot Year\_Birth]{%

            \includegraphics[width=0.45\textwidth]{Img/EDA/EDA001.png}
            \label{fig:PiePlotYearBirth}
    }%
        \subfigure[PiePlot Marital\_Status]{%
            \includegraphics[width=0.45\textwidth]{Img/EDA/EDA002.png}
            \label{fig:PiePlotMaritalStatus}
        }\\ %  ------- End of the first row ----------------------%
        \subfigure[PiePlot di Income]{%
            \includegraphics[width=0.45\textwidth]{Img/EDA/EDA003.png}
            \label{fig:PiePlotIncome}
        }%
%
    \end{center}
\end{figure}

Inoltre si può notare facendo l'istogramma, figura \ref{fig:IstogrammaAge} della variabile \textit{Age} che l'età media degli individui presenti nel dataset è superiore ai 50 anni e dalla figura \ref{fig:IstogrammaEducation} si ha che la maggioranza ha un titolo di studio maggiore o uguale alla laurea e che hanno uno stipendio medio pari a medio alto, \textit{medium-high},  mentre i non laureati hanno uno stipendio medio pari a medio basso, \textit{low-medium}


\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA005.png}
    \caption{Istogramma di Age.}
    \label{fig:IstogrammaAge}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA006.png}
    \caption{BoxPlot di Income e Marital\_Status.}
     \label{fig:BoxPlotMaritalStatus}
  \end{minipage}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA007.png}
    \caption{Istogramma di Education.}
    \label{fig:IstogrammaEducation}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA008.png}
    \caption{BoxPlot di Income ed Education.}
     \label{fig:BoxPlotEducation}
  \end{minipage}
\end{figure}

\newpage
\subsubsection{Total Children}
La maggior parte delle istanze del dataset ha 1 figlio, la variabile Total\_Children è la somma tra la variabile KidHome e TeenHome. Questa informazione si è ricavata eseguendo il codice riportato di seguito.

\begin{figure}[h]
    \centering
    \includegraphics[width=.4\textwidth]{Img/EDA/EDA009.png}
    \caption{Istogramma di Total\_children }
    \label{fig:IstogrammaTc}
\end{figure}

\paragraph{Total\_Childen e Age}
Si è analizzata anche la relazione tra il numero totale di figli, \textit{Total\_children} ed \textit{Age} ed è risultato che tra gli \textit{Adult} il numero di figli più frequente è 1 e che rispetto ai \textit{Senior} hanno più figli.


\begin{figure}[H]
    \centering
    \includegraphics[width=.45\textwidth]{Img/EDA/EDA010.png}
    \caption{Istogramma di Total\_Children e Age}
    \label{fig:IstogrammaTcAge}
\end{figure}
\newpage

\paragraph{Total\_Children e Marital\_Status}
Nel pre processing i valori che può assumere la variabile \textit{Marital\_Status} sono stati collassati in due possibili valori.
\textit{Marital\_Status} è single se la variabile \textit{Marital\_Status}  è \textit{single}, \textit{widow} oppure \textit{divorced}.
E' uguale a 1 se il valore assunto da \textit{Marital\_Status} è \textit{couple} oppure \textit{together}.
Rappresentando il diagramma a barre considerando \textit{Total\_Children}e \textit{Marital\_Status} si ricava che la maggior parte delle istanze ha un figlio. Il numero di istanze con \textit{Marital\_Status} pari a 0 è minore rispetto a quelle con valore uguale a 1 per i casi di zero e due figli, mentre per il caso di tre figli sono molto simili.


\begin{figure}[H]
    \centering
    \includegraphics[width=.4\textwidth]{Img/EDA/EDA011.png}
    \caption{Istogramma di Total\_Children e Marital\_Status}
    \label{fig:IstogrammaTcMaritalStatus}
\end{figure}

Il grafico prendendo in considerazione la variabile \textit{Education} è simile. 

\begin{figure}[H]
    \centering
    \includegraphics[width=.4\textwidth]{Img/EDA/EDA012.png}
    \caption{Istogramma di Total\_Children e Education}
    \label{fig:IstogrammaTcEducation}
\end{figure}

\newpage

\paragraph{Total\_Children e Income}

Sia dall' hist plot che dal jitte rplot si nota che lee istanze che hanno uno stipendio basso hanno più figli rispetto a chi ha uno stipendio alto. Nel caso di due figli ci sono più casi di persone con stipendio \textit{low medium} rispetto a chi ha uno stipendio \textit{low}. 
Nel caso di istanze con stipendio \textit{high} è comune che si abbiano figli. 

\begin{figure}[h!]
\begin{minipage}[c]{0.4\linewidth}
\includegraphics[width=\linewidth]{Img/EDA/EDA013.png}
\caption{Istogramma Income e Total\_Children}
\label{fig:IstogrammaTcIncome}
\end{minipage}
\hfill
\begin{minipage}[c]{0.4\linewidth}
\includegraphics[width=\linewidth]{Img/EDA/EDA014.png}
\caption{ScatterPlot Income e Total\_Children}
\label{fig:ScatterPlotTcIncome}
\end{minipage}%
\end{figure}


\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth]{Img/EDA/EDA015.png}
    \caption{JitterPlot di Total\_Children e Income}
    \label{fig:JitterPlotTcIncome}
\end{figure}

\newpage
\subsubsection{Total Spent}
La maggior parte degli individui spende meno di 500\$.
Facendo il bar-plot della variabile \textit{Total\_Spent} si nota che le istanze presenti nel dataset spendono più per il vino e per la carne.\\
Per poter produrre il grafico della Figura \ref{fig:IstogrammaTs} sono stati sommati i totali che ogni istanza ha speso per un certo prodotto.


\begin{lstlisting}[language=R]
# Plot histogram of total_spent
ggplot(dataSet, aes(x=Total_spent)) + geom_histogram(binwidth = 15, colour = "Black")

# Create dataAcceptedCmp
dataTotalSpent <- data.frame(
  name = c("MntWines", "MntFruits", "MntMeatProducts", "MntFishProducts", "MntSweetProducts", "MntGoldProds"),  
  value = c(sum(dataSet$MntWines), sum(dataSet$MntFruits), sum(dataSet$MntMeatProducts),
            sum(dataSet$MntFishProducts), sum(dataSet$MntSweetProducts), sum(dataSet$MntGoldProds)))

# Barplot of total_spent for each type
ggplot(dataTotalSpent, aes(x=name, y=value)) + 
  geom_bar(stat = "identity", color = "Black") + xlab("Total Spent for each type")  
\end{lstlisting}


\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA016.png}
    \caption{Istogramma Total\_Spent.}
    \label{fig:IstogrammaTs}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA017.png}
    \caption{Istogramma di Total\_Spent distinguendo i tipi di prodotto.}
    \label{fig:IstogrammaTsTypeProduct}
  \end{minipage}
\end{figure}



\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA018.png}
    \caption{Istogramma Wine}
    \label{fig:IstogrammaWine}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA019.png}
    \caption{Istogramma Fruit}
     \label{fig:IstogrammaFruit}
  \end{minipage}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA020.png}
    \caption{Istogramma Meat}
     \label{fig:IstogrammaMeat}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA021.png}
    \caption{Istogramma Fish}
     \label{fig:IstogrammaFish}
  \end{minipage}
\end{figure}


\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA022.png}
    \caption{Istogramma Sweet}
     \label{fig:IstogrammaSweet}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA023.png}
    \caption{Istogramma Gold}
     \label{fig:IstogrammaGold}
  \end{minipage}
\end{figure}

\paragraph{Total Spent e Age}
Osservando la variabile \textit{Total\_Spent} considerando \textit{Age} si ha che la maggior parte degli individui spende meno di 500\$.

\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA024.png}
    \caption{Istogramma di Total\_Spent e Age}
     \label{fig:IstogrammaTsAge}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA025.png}
    \caption{Diagramma di Densità di Total\_Spent e Age}
     \label{fig:DensitaTsAge}
  \end{minipage}
\end{figure}



\newpage
\paragraph{Total Spent e Marital\_Status}
In questo caso sembrano simili. la maggior parte delle coppie spende un totale inferiore a 500\$.
La situazione in single è un po' più rilassata che può essere dovuto al fatto che la maggior parte degli individui nel dataset sono coppie.


\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA026.png}
    \caption{Istogramma di Total\_Spent e Marital\_Status}
    \label{fig:IstogrammaTsMaritalStatus}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA027.png}
    \caption{Diagramma di Densità di Total\_Spent e Marital\_Status }
     \label{fig:DensitaTsMaritalStatus}
  \end{minipage}
\end{figure}

\paragraph{Total Spent ed Education}
I laureati in genere spendono più dei non laureati. la maggior parte dei non laureati spende da 0 a 1500. da 1500 ci sono più casi di laureati che non laureati.
Il grafico della densità   è molto simile a quello della variabile \textit{Marital\_Status}.



\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA028.png}
    \caption{Istogramma di Total\_Spent e Education}
    \label{fig:IstogrammaTsEducation}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA029.png}
    \caption{Diagramma di Densità di Total\_Spent e Education}
     \label{fig:DensitaTsEducation}
  \end{minipage}
\end{figure}

\paragraph{Total Spent e Total\_Children}
Si è studiata la variabile \textit{Total\_Spent} anche per \textit{Total\_Children} e si nota che le istanze che non hanno figli spendono somme maggiori rispetto a quelle in cui il numero di figli è superiore a 0. Questo fatto è più evidente osservando il diagramma di densità rappresentato nella Figura \ref{fig:DensitaTsTc}


\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA030.png}
    \caption{Istogramma di Total\_Spent e Total\_Children}
    \label{fig:IstogrammaTsTc}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA031.png}
    \caption{Diagramma di Densità di Total\_Spent e Total\_Children}
    \label{fig:DensitaTsTc}
  \end{minipage}
\end{figure}

\paragraph{Total\_Spent e Income}
Inoltre analizzando l'istogramma della variabile \textit{Total\_Spent} in relazione ad \textit{Income} che sono direttamente proporizionali infatti nel caso di un \textit{Income} pari a \textit{low} il \textit{Total\_Spent} è basso. 
Per completezza sono stati prodotti anche gli \textit{ScatterPlot} della variabile \textit{Income} e la somma spesa per ogni tipologia di prodotto. Questi grafici sono molto simili tranne quello nella Figura \ref{fig:ScatterPlotIncomeMntMeat}.

\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA033.png}
    \caption{Istogramma di Total\_Spent e Income}
     \label{fig:IstogrammaTsIncome}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA034.png}
    \caption{Diagramma di Densità di Total\_Spent e Income}
     \label{fig:DensitaTsIncome}
  \end{minipage}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA035.png}
    \caption{ScatterPlot Income e MntWines}
     \label{fig:ScatterPlotIncomeMntWines}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA036.png}
    \caption{ScatterPlot Income e MntFruits}
     \label{fig:ScatterPlotIncomeMntFruits}
  \end{minipage}
\end{figure}



\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA037.png}
    \caption{ScatterPlot Income e MntMeatProducts}
     \label{fig:ScatterPlotIncomeMntMeat}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA038.png}
    \caption{ScatterPlot Income e MntFishProducts}
     \label{fig:ScatterPlotIncomeMntFish}
  \end{minipage}
\end{figure}



\paragraph{Total\_Spent JitterPlot+BoxPlot}

\begin{figure}[H]
     \begin{center}
%
        \subfigure[JitterPlot+BoxPlot di Total\_Spent, Income e 
        Marital\_Status.]{%

            \includegraphics[width=0.5\textwidth]{Img/EDA/EDA039.png}
             \label{fig:JitterPlotTsMsIncome}
        }%
        \subfigure[JitterPlot+BoxPlot di Total\_Spent, Income e Total\_Children.]{%
            \includegraphics[width=0.5\textwidth]{Img/EDA/EDA040.png}
             \label{fig:JitterPlotTsTcIncome}
        }\\ %  ------- End of the first row ----------------------%
%
\subfigure[JitterPlot+BoxPlot di Total\_Spent, Income ed Age.]{%
            \includegraphics[width=0.5\textwidth]{Img/EDA/EDA041.png}
             \label{fig:JitterPlotTsIncomeAge}
        }\\ %  ------- End of the first row ----------------------%
%
    \end{center}
\end{figure}

\newpage
\subsubsection{Campaign Analysis}

Si è eseguita un'analisi anche sulle campagne accettate da ogni individuo. 
Per ogni istanza del dataset si sa se ha accettato o meno una campagna. In questo caso le campagne considerate sono cinque e come è possibile osservare dai barplot più di mille istanze non hanno accettato alcuna campagna, mentre chi ha accettato una o più campagne ha scelto la campagna 4.\\

\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA042.png}
    \caption{Istogramma del numero totale di campagne accettate da un'istanza. Total\_Campaign}
    \label{fig:IstogrammaTotalCampaign1}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{Img/EDA/EDA043.png}
    \caption{Istogramma del numero di istanze che ha accettato la campagna i\-esima.}
    \label{fig:IstogrammaTotalCampaign2}
  \end{minipage}
\end{figure}

%%%%%%% 
\newpage
%%%%%%% 

\subsection{PCA}
La PCA è stata prevalentemente sfruttata al fine di ridurre il numero elevato di variabili che descrivono l'insieme di dati a un numero minore di variabili latenti, limitando il più possibile la perdita di informazioni. Il codice seguente mostra parte del codice riportato durante l'analisi dei dati:
\begin{lstlisting}[language=R]
pca <- PCA(dataSet_scaled, graph = FALSE)

#Getting the variance of the first 9 new dimensions
pca$eig[,2][1:9]

#Getting the cummulative variance
pca$eig[,3][1:5]

#Getting the most correlated variables
dimdesc(pca, axes = 1:2)

# get eigenvalue
get_eigenvalue(pca)

# visualize pca
fviz_eig(pca, addlabels = TRUE, ylim = c(0, 50))
fviz_contrib(pca, choice = "var", axes = 1, top = 5)
fviz_pca_biplot(pca)

#Creating a factor map for the variable contributions
fviz_pca_var(pca, col.var = "contrib", repel = TRUE)

fviz_pca_var(pca, select.var = list(contrib = 5), col.var = "contrib", repel = TRUE)

# Extract the principal components
pcaTraining <- PCA(trainingSet_scaled, graph = FALSE)
trainingSet_input <- data.frame(get_pca_ind(pcaTraining)$coord)
\end{lstlisting}
Da esso si vuole dare particolare attenzione alla funzione \textit{get\_eigenvalue(pca)} che fornire le informazioni rappresentate nella tabella \ref{fig:get_eigenvalue(pca)}. Si vuole anche fornire un riferimento grafico a quest'ultima tramite l'output della funzione \textit{fviz\_eig(pca, addlabels = TRUE, ylim = c(0, 50))} descritto dalla figura \ref{fig:fviz_eig(pca, addlabels = TRUE, ylim = c(0, 50))}. Da essa si può notare che le prime 5 dimensioni fornite dalla PCA forniscono il 70\% della varianza cumulativa, per questo motivo si è deciso di prendere in considerazione tali dimensioni. Inoltre si vuole sottolineare l'importanza della prima dimensione che riesce a spiegare più del 40\% della varianza dei dati.
\begin{table}[H]
\centering
\begin{tabular}{rrrr}
  \hline
 & eigenvalue & variance.percent & cumulative.variance.percent \\ 
  \hline
Dim.1 & 7.00 & 41.15 & 41.15 \\ 
  Dim.2 & 1.75 & 10.31 & 51.46 \\ 
  Dim.3 & 1.14 & 6.69 & 58.15 \\ 
  Dim.4 & 1.08 & 6.34 & 64.49 \\ 
  Dim.5 & 1.00 & 5.86 & 70.34 \\ 
  Dim.6 & 0.77 & 4.54 & 74.88 \\ 
  Dim.7 & 0.66 & 3.86 & 78.74 \\ 
  Dim.8 & 0.62 & 3.64 & 82.38 \\ 
  Dim.9 & 0.58 & 3.38 & 85.76 \\ 
  Dim.10 & 0.46 & 2.73 & 88.49 \\ 
  Dim.11 & 0.43 & 2.52 & 91.00 \\ 
  Dim.12 & 0.39 & 2.31 & 93.31 \\ 
  Dim.13 & 0.35 & 2.04 & 95.35 \\ 
  Dim.14 & 0.31 & 1.83 & 97.18 \\ 
  Dim.15 & 0.26 & 1.52 & 98.70 \\ 
  Dim.16 & 0.22 & 1.30 & 100.00 \\ 
  Dim.17 & 0.00 & 0.00 & 100.00 \\ 
   \hline
\end{tabular}
\caption{Output funzione \textit{get\_eigenvalue(pca)}}
\label{fig:get_eigenvalue(pca)}
\end{table}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Img/PCA/PCA001.png}
    \caption{Output funzione \textit{fviz\_eig(pca, addlabels = TRUE, ylim = c(0, 50))}}
    \label{fig:fviz_eig(pca, addlabels = TRUE, ylim = c(0, 50))}
\end{figure}
In particolare la tabella \ref{fig:pca$var$contrib} vuole far notare il contributo di ciascun attributo del dataset nella creazione delle dimensioni della pca. Da essa possiamo notare le cinque principali variabili che hanno contribuito maggiormente nella creazione della prima dimensione della \textit{principal component analysis}: Total\_spent, MntMeatProducts, NumCatalogPurchases, MntWines e Income. La figura \ref{fig:fviz_contrib(pca, choice = "var", axes = 1, top = 5)} ne mostra un grafico più esplicativo.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Img/PCA/PCA002.png}
    \caption{Output funzione \textit{fviz\_contrib(pca, choice = "var", axes = 1, top = 5)}}
    \label{fig:fviz_contrib(pca, choice = "var", axes = 1, top = 5)}
\end{figure}
\begin{table}[H]
\centering
\begin{tabular}{rrrrrr}
  \hline
 & Dim.1 & Dim.2 & Dim.3 & Dim.4 & Dim.5 \\ 
  \hline
Income & 7.73 & 0.16 & 1.54 & 4.61 & 0.91 \\ 
  Recency & 0.00 & 0.00 & 0.25 & 10.43 & 88.32 \\ 
  MntWines & 8.82 & 5.02 & 11.32 & 0.32 & 0.19 \\ 
  MntFruits & 6.94 & 1.20 & 11.53 & 0.33 & 0.06 \\ 
  MntMeatProducts & 9.58 & 1.08 & 0.06 & 0.00 & 0.13 \\ 
  MntFishProducts & 7.46 & 1.42 & 9.96 & 0.10 & 0.04 \\ 
  MntSweetProducts & 6.89 & 0.75 & 9.12 & 0.32 & 0.05 \\ 
  MntGoldProds & 4.66 & 2.42 & 5.33 & 2.54 & 0.40 \\ 
  NumDealsPurchases & 0.26 & 36.20 & 4.32 & 0.71 & 0.11 \\ 
  NumWebPurchases & 4.10 & 18.79 & 0.53 & 2.07 & 0.00 \\ 
  NumCatalogPurchases & 9.60 & 0.11 & 0.43 & 0.25 & 0.05 \\ 
  NumStorePurchases & 7.55 & 3.44 & 0.43 & 0.29 & 0.31 \\ 
  NumWebVisitsMonth & 5.66 & 9.62 & 0.01 & 12.58 & 1.15 \\ 
  Total\_spent & 13.03 & 0.57 & 1.12 & 0.30 & 0.17 \\ 
  Total\_Campains & 2.71 & 0.06 & 42.35 & 6.21 & 1.26 \\ 
  Total\_Childs & 4.78 & 13.94 & 0.53 & 2.94 & 0.05 \\ 
  Age & 0.22 & 5.20 & 1.15 & 55.99 & 6.81 \\ 
   \hline
\end{tabular}
\caption{Output \textit{pca\$var\$contrib}}
\label{fig:pca$var$contrib}
\end{table}
Le funzioni \textit{fviz\_pca\_var} hanno permesso di analizzare graficamente le dimensioni che spiegano il contributo delle variabili considerate nelle prime due dimensioni (fig. \ref{fig:fvizpcavar1} e fig. \ref{fig:fvizpcavar2}).

\begin{figure}[H]
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=1\linewidth]{Img/PCA/PCA005.png}
     \caption{Contributo di tutte la variabili sulle prime due dimensioni.}\label{fig:fvizpcavar1}
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=1\linewidth]{Img/PCA/PCA004.png}
     \caption{Contributo delle cinque variabili più significative sulle prime due dimensioni.}\label{fig:fvizpcavar2}
   \end{minipage}
\end{figure}
In fine si è preso in considerazione un nuovo dataset, nato dalle dimensioni fornite dalla PCA, descritto dalla tabella \ref{fig:PCADataset}. Esso verrà sfruttato durante l'analisi del dataset tramite i alcuni degli algoritmi utilizzati.

\begin{table}[h!t] % fai rimanere h!t 
\centering
\begin{tabular}{rrrrrr}
  \hline
 & Dim.1 & Dim.2 & Dim.3 & Dim.4 & Dim.5 \\ 
  \hline
1 & 4.15 & 0.41 & 1.40 & 0.12 & 0.27 \\ 
  2 & -2.56 & -0.14 & -0.62 & 1.48 & -0.78 \\ 
  3 & 1.81 & -0.22 & 0.42 & 0.13 & -1.15 \\ 
  4 & -2.46 & -0.91 & 0.29 & -0.99 & -0.58 \\ 
  5 & -0.24 & 0.50 & 1.19 & 0.05 & 1.42 \\ 
  6 & 0.65 & 0.73 & -0.16 & -0.19 & -1.22 \\ 
   \hline
\end{tabular}
\caption{\textit{Head} del Dataset fornito dalla PCA}
\label{fig:PCADataset}
\end{table}

%%%%%%% BLANKPAGE

%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                              %
%                                                              %
%                                                              %
%                         NEW SECTION                          %
%                                                              %
%                                                              %
%                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Modelli utilizzati}
Il dataset non presenta una variabile target specifica, per questo motivo di è ritenuto opportuno analizzare il tutto mediante algoritmi non supervisionati come quelli di \textbf{clustering}. In particolare si è deciso di utilizzare principalmente l'algoritmo \textbf{K-Means}. Oltre a ciò si è anche cercato di trovare un target su cui poter fare predizioni mediante alberi decisionali.


\subsection{K-Means}
La natura stessa dei dati ha comportato l'obbligo di analizzare il tutto mediante un algoritmo come \textbf{K-Means}. 

\subsubsection{Silhouette e Elbow Method}
Si è ritenuto opportuno utilizzare metodi come \textbf{Elbow Method} e \textbf{Silhouette} al fine di determinare il numero ottimale di \textbf{clusters} da utilizzare. 
\begin{lstlisting}[language=R]
set.seed(6)
wcss <- vector()
for (i in 1:10) {
  wcss[i] <- sum(kmeans(dataSet_scaled, i)$withinss)
}
plot(1:10, wcss, type="b", main = paste('Clusters'), xlab='Number of clusters', ylab="WCSS")

# OR

fviz_nbclust(dataSet_scaled,kmeans,method="wss")+geom_vline(xintercept=2,linetype=2)
\end{lstlisting}
Il codice mostra una prima analisi mediante \textit{elbow method}, il cui output si può notare dalle figure \ref{fig:Elbow1} e \ref{fig:Elbow2}. Esse mostrano un'inclinazione tra un numero di clusters compreso tra 2 e 3.
\begin{figure}[H]
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=1\linewidth]{Img/K-MEANS/KMEANS001.png}
     \caption{Elbow Method effettuato manualmente}\label{fig:Elbow1}
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=1\linewidth]{Img/K-MEANS/KMEANS002.png}
     \caption{Elbow Method effettuato automaticamente dal metodo $fviz\_nbclust$}\label{fig:Elbow2}
   \end{minipage}
\end{figure}
Per maggior sicurezza si è quindi deciso di sfruttare anche il metodo \textit{Silhouette} mediante il codice sottostante.

\begin{lstlisting}[language=R]
k <- 2:10
avg_sil <- sapply(k, silhouette_score)
plot(k, type='b', avg_sil, xlab='Number of clusters', ylab='Average Silhouette Scores', frame=FALSE)
avg_sil # <<<- important

# OR
fviz_nbclust(dataSet_scaled, kmeans, method="silhouette")
\end{lstlisting}
Il codice presenta in output i grafici espressi della figura \ref{fig:Silhouette2}, da cui si è potuto constatare con maggior sicurezza l'utilizzo di un numero di clusters pari a 2. 
\begin{figure}[H]
        \centering
     \includegraphics[width=0.7\linewidth]{Img/K-MEANS/KMEANS004.png}
     \caption{Silhouette effettuata automaticamente dal metodo $fviz\_nbclust$}\label{fig:Silhouette2}
\end{figure}

\subsubsection{Algoritmo e Analisi}
Il codice sottostante viene espresso mediante le figure  \ref{fig:clusters} e \ref{fig:dissimilaritymatrix} che rappresentano rispettivamente il \textbf{partizionamento per ogni cluster} e la \textbf{Matrice di dissimilarità}. E' doveroso notare che entrambe le figure mostrano un buon partizionamento degli elementi del cluster, sebbene ci sia qualche elemento di intersezione tra i due.
\begin{lstlisting}[language=R]
set.seed(29)
km <- kmeans(dataSet_scaled, 2, nstart = 10)
print(km$centers)
fviz_cluster(km, dataSet_scaled, geom = "point",ellipse.type = "norm",repel = TRUE)
cl <- km$cluster
dissplot(dist(dataSet_scaled), labels=cl,options=list(main="Kmeans Clustering With k=2"))
\end{lstlisting}

\begin{figure}[H]
   \begin{minipage}{0.48\textwidth}
     \centering
         \includegraphics[width=1\textwidth]{Img/K-MEANS/KMEANS005.png}
    \caption{Partizionamento in clusters dei dati}
    \label{fig:clusters}
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=1\linewidth]{Img/K-MEANS/KMEANS006.png}
     \caption{Dissimilarity matrix}\label{fig:dissimilaritymatrix}
   \end{minipage}
\end{figure}
In particolare la figura \ref{fig:clusters} presenta gli elementi all'interno di ogni cluster. La tabella \ref{fig:clustersnumberelements} mostra il numero preciso di elementi per ogni cluster.
\begin{table}[H]
\centering
\begin{tabular}{rlr}
  \hline
 & cluster & n \\ 
  \hline
1 & 1 & 874 \\ 
  2 & 2 & 1366 \\ 
   \hline
\end{tabular}
\caption{Numero di elementi per ogni cluster}
\label{fig:clustersnumberelements}
\end{table}
Si è ritenuto necessario analizzare i risultati ottenuti mediante le variabili più significative, sorte durante la \textit{Principal Component Analisys}. 
\begin{lstlisting}[language=R]
wines <- ggplot(dataSet, aes(MntWines)) + 
   facet_grid(cluster~.) 

wines + geom_histogram(color = "black", fill = "red") 
wines + geom_density(fill="red", position = "Stack")
ggplot(dataSet, aes(x=cluster,y=MntWines,fill=cluster))+geom_boxplot(outlier.colour="black")
\end{lstlisting}
Il codice soprastante è descritto dalle figure \ref{fig:winesKmeansBoxPlot}, \ref{fig:winesKmeansDensity} e \ref{fig:winesKmeansHistogram}. Dall'analisi dei grafici si nota una spesa maggiore di vini per i \textit{customers} all'interno del primo cluster. In particolare la maggior parte dei clienti all'interno del secondo cluster non ha acquistato vini negli ultimi due anni. 

\begin{figure}[H]
   \begin{minipage}{0.48\textwidth}
     \centering
         \includegraphics[width=1\textwidth]{Img/K-MEANS/KMEANS007.png}
    \caption{Istogramma della variabile Wines in relazione al numero di cluster}
    \label{fig:winesKmeansHistogram}
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=1\linewidth]{Img/K-MEANS/KMEANS008.png}
     \caption{Diagramma di densità della variabile Wines in relazione al numero di cluster}\label{fig:winesKmeansDensity}
   \end{minipage}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Img/K-MEANS/KMEANS009.png}
    \caption{BoxPlot della variabile Wines in relazione al numero di cluster}
    \label{fig:winesKmeansBoxPlot}
\end{figure}

\begin{lstlisting}[language=R]
income <- ggplot(dataSet, aes(Income))+ 
  facet_grid(cluster~.) + 
  xlim(0,200000)

income +  geom_histogram(color = "black", fill = "green")
income + geom_density(fill="green", position = "Stack")
ggplot(dataSet, aes(x=cluster,y=Income,fill=cluster))+geom_boxplot(outlier.colour="black") + ylim(0,200000)
\end{lstlisting}
Il codice appena descritto ha il compito di analizzare gli elementi dei cluster in relazione al reddito di ciascun utente, ovvero in relazione alla variabile \textit{income}. Le figure \ref{fig:incomeKmeansDensity}, \ref{fig:incomeKmeansHistogram} e \ref{fig:incomeKmeansBoxPlot} ne mostrano la rappresentazione dei grafici. Da esse è doverso notare che nel secondo cluster la maggior parte dei clienti possiede un reddito generalmente più basso rispetto ai \textit{customers} facenti parte del primo. Calcolando il reddito medio dei compratori, pari a 52247 dollari, si può anche notare che la maggior parte degli elementi nel secondo cluster possiedono un il reddito inferiore alla media. E' opportuno notare anche che, la maggior parte degli utenti del primo raggruppamento, contrariamente ai primi, possiedono un reddito superiore alla media.

\begin{figure}[H]
   \begin{minipage}{0.48\textwidth}
     \centering
         \includegraphics[width=1\textwidth]{Img/K-MEANS/KMEANS010.png}
    \caption{Istogramma della variabile Income in relazione al numero di cluster}
    \label{fig:incomeKmeansHistogram}
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=1\linewidth]{Img/K-MEANS/KMEANS011.png}
     \caption{Diagramma di densità della variabile Income in relazione al numero di cluster}\label{fig:incomeKmeansDensity}
   \end{minipage}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Img/K-MEANS/KMEANS012.png}
    \caption{BoxPlot della variabile income in relazione al numero di cluster}
    \label{fig:incomeKmeansBoxPlot}
\end{figure}

Un'altra variabile analizzata è Total\_spent, che spiega la gran parte della varianza della prima dimensione della PCA. Il codice sottostante speiga le figure \ref{fig:TotalSpentKmeansBoxPlot}, \ref{fig:TotalSpentKmeansDensity} e \ref{fig:TotalSpentKmeansHistogram}. In particolare, dall'analisi di esse è emerso che i compratori del secondo cluster generalmente spendono molto meno denaro rispetto a quelli del primo. Oltre a ciò si può anche notare che quest'ultimi versano mediamente più di mille dollari ogni due anni per prodotti come: vino, frutta, pesce e carne.
\begin{lstlisting}[language=R]
ts <- ggplot(dataSet, aes(Total_spent), colour=cluster) + facet_grid(cluster~.)
ts + geom_histogram(color = "black", fill = "purple") 
ts + geom_density(fill="purple", position = "Stack")
ggplot(dataSet, aes(x=cluster,y=Total_spent,fill=cluster))+geom_boxplot(outlier.colour="black")
\end{lstlisting}
\begin{figure}[H]
   \begin{minipage}{0.48\textwidth}
     \centering
         \includegraphics[width=1\textwidth]{Img/K-MEANS/KMEANS013.png}
    \caption{Istogramma della variabile Total\_spent in relazione al numero di cluster}
    \label{fig:TotalSpentKmeansHistogram}
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=1\linewidth]{Img/K-MEANS/KMEANS014.png}
     \caption{Diagramma di Densità della variabile Total\_spent in relazione al numero di cluster}\label{fig:TotalSpentKmeansDensity}
   \end{minipage}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Img/K-MEANS/KMEANS015.png}
    \caption{BoxPlot della variabile Total\_spent in relazione al numero di cluster}
    \label{fig:TotalSpentKmeansBoxPlot}
\end{figure}

Le figure \ref{fig:NumCatalogPurchasesKmeansBoxPlot}, \ref{fig:NumCatalogPurchasesKmeansDensity} e \ref{fig:NumCatalogPurchasesKmeansHistogram} mostrano che i clienti del secondo cluster effettuino compere sul catalogo generalmente in quantità minore rispetto a quelli del primo. Difatti ques'ultimi acquistano mediamente 5 prodotti dal catalogo.
\begin{lstlisting}[language=R]
numCatalogPurchases <- ggplot(dataSet, aes(NumCatalogPurchases)) +  facet_grid(cluster~.)
numCatalogPurchases + geom_histogram(color = "black", fill = "blue") 
numCatalogPurchases + geom_density(fill="blue", position = "Stack")
ggplot(dataSet, aes(x=cluster,y=NumCatalogPurchases,fill=cluster))+geom_boxplot(outlier.colour="black") + ylim(0,10)
\end{lstlisting}

\begin{figure}[H]
   \begin{minipage}{0.48\textwidth}
     \centering
         \includegraphics[width=1\textwidth]{Img/K-MEANS/KMEANS016.png}
    \caption{Istogramma della variabile NumCatalogPurchases in relazione al numero di cluster}
    \label{fig:NumCatalogPurchasesKmeansHistogram}
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=1\linewidth]{Img/K-MEANS/KMEANS017.png}
     \caption{Diagramma di Densità della variabile NumCatalogPurchases in relazione al numero di cluster}\label{fig:NumCatalogPurchasesKmeansDensity}
   \end{minipage}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Img/K-MEANS/KMEANS018.png}
    \caption{BoxPlot della variabile NumCatalogPurchases in relazione al numero di cluster}
    \label{fig:NumCatalogPurchasesKmeansBoxPlot}
\end{figure}

Dall'analisi della variabile \textit{MntMeatProducts}, inerente all'acquisto di prodotti di carne negli ultimi due anni, si possono evincere alcune importanti informazioni correlate anche alla precedente analisi di \textit{Total\_spent}. In particolare le figure \ref{fig:MntMeatProductsKmeansBoxPlot}, \ref{fig:MntMeatProductsKmeansDensity} e \ref{fig:MntMeatProductsKmeansHistogram} mostrano come gli acquirenti del secondo raggruppamento tendano a spendere generalmente di meno rispetto a quelli del primo. Difatti i secondi acquistano sicuramente molto meno rispetto alla media. In particolare si noti la differenza di circa 170 dollari spesi per prodotti di carne (in un arco temporale di due anni).

\begin{lstlisting}[language=R]
meat <- ggplot(dataSet, aes(MntMeatProducts)) +  facet_grid(cluster~.)
meat + geom_histogram(color = "black", fill = "brown") 
meat + geom_density(fill="brown", position = "Stack")
ggplot(dataSet, aes(x=cluster,y=MntMeatProducts,fill=cluster))+geom_boxplot(outlier.colour="black")
\end{lstlisting}


\begin{figure}[H]
   \begin{minipage}{0.48\textwidth}
     \centering
         \includegraphics[width=1\textwidth]{Img/K-MEANS/KMEANS019.png}
    \caption{Istogramma della variabile MntMeatProducts in relazione al numero di cluster}
    \label{fig:MntMeatProductsKmeansHistogram}
   \end{minipage}\hfill
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=1\linewidth]{Img/K-MEANS/KMEANS020.png}
     \caption{Diagramma di Densità della variabile MntMeatProducts in relazione al numero di cluster}\label{fig:MntMeatProductsKmeansDensity}
   \end{minipage}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Img/K-MEANS/KMEANS021.png}
    \caption{BoxPlot della variabile MntMeatProducts in relazione al numero di cluster}
    \label{fig:MntMeatProductsKmeansBoxPlot}
\end{figure}


\newpage
\subsection{Decision Tree}
Usando il dataset ricavato dalla PCA ovvero \textit{trainingSet\_input} e \textit{testSet\_input} si è cercato di fare una previsione sul valore che assume la variabile \textit{Response}. Per farlo è stata aggiunta una variabile al dataset. 

\begin{lstlisting}[language=R]
trainingSet_input$Response <- trainingSet$Response
testSet_input$Response <- testSet$Response
\end{lstlisting}

Successivamente è stata usata la funzione \textit{rpart} per costruire un albero di decisione indicando come formula la variabile \textit{Response}.

\begin{lstlisting}[language=R]
classifier <- rpart(Response ~ ., data = trainingSet_input, method = "class")
\end{lstlisting}

Per visualizzarlo si è eseguita la funzione prp del \textit{package, rpart.plot} indicando per i campi richiesti un parametro come per esempio \textit{type} che assegna a tutti i nodi un etichetta, non solo le foglie. \textit{extra}, che se uguale ad 1 visualizza il numero di osservazioni che cadono nel nodo. 

\begin{lstlisting}[language=R]
prp(classifier, 
     type = 1, extra = 1, varlen = -10, 
     box.col = ifelse(classifier$frame$var == "<leaf>", 'gray', 'white'))
\end{lstlisting}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Img/D-TREE/D-TREE001.png}
    \caption{DecisionTree response.default.tree}
\end{figure}


Successivamente si è eseguita una previsione sulla variabile \textit{Response} tramite la funzione \textit{predict} passando come parametro anche l'albero \textit{classifier}. 

\begin{lstlisting}[language=R]
y_pred <- predict(classifier, testSet_input, type = "class")
\end{lstlisting}

Per confrontare il valore effetivo della variabile \textit{Response}, colonna 6 del \textit{testSet\_input}  e della previsione si è fatta la matrice di confusione. 

\begin{lstlisting}[language=R]
cm = table(testSet_input[,6],y_pred)
\end{lstlisting}



\begin{table}[h!]
\centering
\begin{tabular}{|ll|lll|}
\hline
\multicolumn{2}{|l|}{\multirow{2}{*}{}} & \multicolumn{3}{l|}{Prediction}                        \\ \cline{3-5} 
\multicolumn{2}{|l|}{}                  & \multicolumn{1}{c|}{\_} & \multicolumn{1}{l|}{0}  & 1  \\ \hline
\multicolumn{2}{|l|}{\multirow{2}{*}{Reference}} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{366} & 15 \\ \cline{3-5} 
\multicolumn{2}{|l|}{}                  & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{59} & 8 \\ \hline
\end{tabular}
\end{table}

Dalla matrice di confusione sommando i valori presenti nella diagonale e facendo il rapporto con la somma di tutti i valori della matrice si ricava che l'accuratezza è del 83.48\%.
Di seguito sono riportati altri dati statistici che è possibile ricavare. 

\begin{table}[h!]
\centering
\begin{tabular}{ll}
\multicolumn{2}{l}{\textbf{Positive Class:} 1} \\
\textbf{Accuracy:} 0.8348 & \textbf{Precision:} 0.1194\\
\textbf{Recall:} 0.3478 & \textbf{F-Measure:} 0.1777
\end{tabular}
\end{table}

Per capire meglio l'albero decisionale si usa la funzione printcp().

\begin{lstlisting}[language=R]
cv.ct <- rpart( Response ~ ., data = trainingSet_input, method ="class", cp = 0, minsplit = 2, xval = 10)
printcp(cv.ct)
\end{lstlisting}

\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
  \hline
 & CP & nsplit & rel error & xerror & xstd \\ 
  \hline
1 & 0.0880150 & 0 & 0.00000 & 1.00000 & 0.056456 \\ 
  2 & 0.0131086 & 2 & 0.823970 & 0.84270 & 0.052535 \\ 
  3 & 0.0074906 & 6 & 0.771536 & 0.85393 & 0.052833 \\ 
  4 & 0.0056180 & 9 & 0.749064 & 0.91386 & 0.054375 \\ 
  5 & 0.0049938 & 32 & 0.554307 & 0.91386 & 0.054375 \\ 
  6 & 0.0037453 & 38 & 0.524345 & 0.91386 & 0.054375 \\ 
  7 & 0.0028090 & 98 & 0.299625 & 0.99625 & 0.056369 \\ 
  8 & 0.0024969 & 114 & 0.250936 & 1.04494 & 0.057483 \\ 
  9 & 0.0022472 & 123 & 0.228464 & 1.04494 & 0.057483 \\ 
  10 & 0.0018727 & 128 & 0.217228 & 1.11236 & 0.058955 \\ 
  11 & 0.0012484 & 202 & 0.052434 & 1.11236 & 0.058955 \\ 
  12 & 0.000000 & 205 & 0.048689 & 1.11985 & 0.059113 \\ 
   \hline
\end{tabular}
\end{table}

Succesivamente si è cercato di evitare \textit{overfitting} semplificando l'albero di decisione cercando prendendo prima il minimo tra una matrice di informazioni sulle strutture ottimali in base ad un parametro di complessità, cp dalla\textit{cptable} che è pari a 0.84644.
Poi si è cercato l'errore standard corrispondente al minimo errore che è 0.0526.  

\begin{lstlisting}[language=R]
# min error
minerror <- min(cv.ct$cptable[ , 4])
minerrorstd <- cv.ct$cptable[cv.ct$cptable[,4] == minerror, 5]

simplertrees <- cv.ct$cptable[cv.ct$cptable[,4] < minerror + minerrorstd, ]

bestcp <- simplertrees[1, 1]
\end{lstlisting}
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
  \hline
 & CP & nsplit & rel error & xerror & xstd \\ 
  \hline
  2 & 0.013108614 & 2 & 0.8239700 & 0.8464419 & 0.05263442 \\ 
  3 & 0.007490637  & 6 & 0.7715356 & 0.8838951 & 0.05361429 \\ 
  
   \hline
\end{tabular}
\end{table}

Si ricava l'insieme di alberi in cui xerror e minore della somma tra minerror e minerrorstd e da esso si trova che il parametro di complessità, cp è 0.01310861. 

\begin{lstlisting}[language=R]
bestcp <- simplertrees[1, 1]
\end{lstlisting}
L'albero più semplice si può visualizzare eseguendo le istruzioni successive.

\begin{lstlisting}[language=R]
response.best.tree <- prune( cv.ct, cp = bestcp )
prp(response.best.tree, type = 1, extra = 1, varlen = -15, cex = 0.5,
     box.col = ifelse(response.best.tree$frame$var == "<leaf>", 'gray', 'white' ))
\end{lstlisting}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Img/D-TREE/D-TREE002.png}
    \caption{DecisionTree response.best.tree}
\end{figure}


Come per l'albero precedente prima di visualizzare la matrice di confusione ed altri dati statistici si è fatta una previsione.

\begin{lstlisting}[language=R]
response.best.tree.pred <- predict(response.best.tree, testSet_input, type = "class")
\end{lstlisting}

Ed in fine per confrontare il valore effetivo della variabile \textit{Response} e della previsione si è fatta la matrice di confusione. 

\begin{lstlisting}[language=R]
confusionMatrix<-confusionMatrix(response.best.tree.pred, as.factor(testSet_input$Response), positive = "1", mode = "prec_recall") 
\end{lstlisting}

\begin{table}[h!]
\centering
\begin{tabular}{|ll|lll|}
\hline
\multicolumn{2}{|l|}{\multirow{2}{*}{}} & \multicolumn{3}{l|}{Prediction}                        \\ \cline{3-5} 
\multicolumn{2}{|l|}{}                  & \multicolumn{1}{c|}{\_} & \multicolumn{1}{l|}{0}  & 1  \\ \hline
\multicolumn{2}{|l|}{\multirow{2}{*}{Reference}} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{355} & 57 \\ \cline{3-5} 
\multicolumn{2}{|l|}{}                  & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{26} & 10 \\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{ll}
\multicolumn{2}{l}{\textbf{Positive Class:} 1} \\
\textbf{Accuracy:} 0.8147 & \textbf{Precision:} 0.27778\\
\textbf{Recall:} 0.14925 & \textbf{F-Measure:} 0.19417
\end{tabular}
\end{table}

%%%%%%% 

%%%%%%% 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                              %
%                                                              %
%                                                              %
%                         NEW SECTION                          %
%                                                              %
%                                                              %
%                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Esperimenti}
Per valutare l'efficacia del modello supervisionato \textit{Decision-Tree} sul dataset si sono creati 10 \textit{fold} tramite la funzione \textit{ceateFolds} successivamente sui fold creati si è eseguita una funzione che si ocuppa di trovare la matrice di ricavare la matrice di confusione per ogni \textit{fold}. 


\begin{lstlisting}[language=R]
# applying  k-fold cross validation
folds= createFolds(trainingSet_input$Response, k=10)
cv = lapply(folds, function(x){
  
  training_fold= trainingSet_input[-x,]
  test_fold= trainingSet_input[x,]
  # building the classifier
  response.default.tree <- rpart(Response ~ ., data = training_fold,  method = "class")
  
  # predicting values
  response.default.tree.pred <- predict(response.default.tree, newdata = test_fold, type = "class")
 
  cm = table(test_fold[,6], response.default.tree.pred)
  return (cm)
})
\end{lstlisting}

Per ricavare la matrice di confusione complessiva si riduce la lista di matrici rappresentate da \textit{cv}in unica matrice tramite l'istruzione \textit{Reduce()} l'insieme di matrici. 

\begin{lstlisting}[language=R]
complex_cf =Reduce('+',  cv)
complex_cf
\end{lstlisting}


\begin{table}[h!]
\centering
\begin{tabular}{|ll|lll|}
\hline
\multicolumn{2}{|l|}{\multirow{2}{*}{}} & \multicolumn{3}{l|}{Prediction}                        \\ \cline{3-5} 
\multicolumn{2}{|l|}{}                  & \multicolumn{1}{c|}{\_} & \multicolumn{1}{l|}{0}  & 1  \\ \hline
\multicolumn{2}{|l|}{\multirow{2}{*}{Reference}} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{1488} & 37 \\ \cline{3-5} 
\multicolumn{2}{|l|}{}                  & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{200} & 67 \\ \hline
\end{tabular}
\end{table}

Successivamente si sono ricavati i valori di \textit{Accuracy}, \textit{Precision}, \textit{Recall} e \textit{F-measure}.

\begin{lstlisting}[language=R]
accuracy = sum(diag(complex_cf))/sum(complex_cf)
precision = (complex_cf[2,2] /sum(complex_cf[2,1], complex_cf[2,2]))
recall = (complex_cf[2,2] /sum(complex_cf[2,2], complex_cf[1,2]))
fmeasure = (2*precision*recall)/(precision+recall)
\end{lstlisting}

\begin{table}[h!]
\centering
\begin{tabular}{ll}
\textbf{Accuracy:} 0.8677 & \textbf{Precision:} 0.2509\\
\textbf{Recall:} 0.6442 & \textbf{F-Measure:} 0.3611
\end{tabular}
\end{table}

Essendo un problema in cui la classificazione è binaria si è definita la curva di ROC, che rappresenta il tasso dei veri positivi (TPR) in funzione del tasso dei falsi positivi  (FPR) e si è ricavato che AUC, l'area sotto la curva è pari al 0.5457 cioè  la probabilità che il modello classifichi un esempio positivo casuale in modo più elevato rispetto a un esempio negativo casuale.

\begin{lstlisting}[language=R]
treefit=  rpart(Response ~ ., data = trainingSet_input, method = "class")
predTree = predict(dtreefit,testSet_input[, !names(testSet_input) %in% c("Response")], probability=TRUE)

predTReeToRoc = pred[, 2]
pred.to.roc
predRocr = prediction(predTReeToRoc, testSet_input$Response)
perfRocr = performance(predRocr, measure = "auc", x.measure = "cutoff")
perfTprRocr = performance(predRocr, "tpr","fpr")
plot(perfTprRocr, colorize=T,main=paste("AUC:",(perfRocr@y.values)))
abline(a=0, b=1)
\end{lstlisting}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{Img/[D-TREE] Model Evalutation/plot.png}
    \caption{Grafico rappresentante la curva ROC}
\end{figure}


%%%%%%% 
\blankpage
%%%%%%% 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                              %
%                                                              %
%                                                              %
%                         NEW SECTION                          %
%                                                              %
%                                                              %
%                                                              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Conclusioni}

Questa sperimentazione ha avuto l'obiettivo di analizzare un insieme di dati mediante tecniche di machine learning differenti, in particolare mediante un algoritmo di tipo supervisionato, \textit{\textbf{Decision Tree}} ed un algoritmo non supervisionato cioè  \textit{\textbf{K-Means}}. Risulta che sul dataset scelto l'algoritmo che si comporta meglio sia \textit{K-Means} che dall'analisi dei dati riscontrati si può giungere alla conclusione che una buona suddivisione dei dati riportati può avvenire mediante l'utilizzo di due cluster. In particolare il secondo cluster presenta clienti con un reddito generalmente al di sotto della media e sicuramente minore rispetto alla maggior parte dei compratori facenti parte della prima divisione. Secondo i dati analizzati ciò ha comportato indubbiamente una riduzione delle spese totali da parte degli elementi all'interno del primo gruppo. La riduzione del numero di acquisti di prodotti ha generalmente toccato elementi che variano dai vini fino alla carne. 

\end{document}
